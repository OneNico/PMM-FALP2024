{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Proyecto: Clasificación de Mamografías utilizando el dataset VinDr-Mammo\n",
    "\n",
    "Este proyecto tiene como objetivo implementar un sistema de clasificación de mamografías para detectar tejido canceroso. El flujo de trabajo se ha dividido en tres partes, cada una encargada de un área específica del proyecto. A continuación, se describen las tareas detalladas, las entradas y salidas esperadas de cada fase, y cómo se conectan entre sí para construir el sistema completo.\n",
    "\n",
    "---\n",
    "\n",
    "## Integrante 1: Preprocesamiento de Datos y Aumento de Datos\n",
    "\n",
    "### **Entrada**:\n",
    "- **Dataset VinDr-Mammo**: \n",
    "  - **Imágenes DICOM** de mamografías con vistas diferentes.\n",
    "  - **Archivos CSV de anotaciones**: Contienen las coordenadas de las Regiones de Interés (ROI) y las etiquetas de clasificación (normal, benigno, maligno).\n",
    "\n",
    "### **Tareas**:\n",
    "1. **Conversión de Imágenes DICOM a Formatos PNG/JPEG**:\n",
    "   - Cargar las imágenes en formato DICOM utilizando librerías como PyDicom.\n",
    "   - Convertir las imágenes a formatos manejables (PNG o JPEG).\n",
    "   - Redimensionar las imágenes a un tamaño adecuado para el modelo VGG16 (por ejemplo, 299x299 píxeles).\n",
    "\n",
    "2. **Extracción de Regiones de Interés (ROI)**:\n",
    "   - Utilizar las coordenadas presentes en los archivos CSV de anotaciones para recortar las imágenes y obtener las ROI (Regiones de Interés).\n",
    "   - Generar imágenes de estas ROI que representen las áreas donde se detectaron anomalías (benignas o malignas).\n",
    "\n",
    "3. **Aumento de Datos (Data Augmentation)**:\n",
    "   - Aplicar técnicas de aumento de datos a las imágenes y las ROI para aumentar el tamaño del conjunto de datos:\n",
    "     - **Rotaciones aleatorias**, **inversión horizontal y vertical**, **ajustes de brillo y contraste**, entre otras.\n",
    "   - Generar múltiples versiones de cada imagen para mejorar la generalización del modelo.\n",
    "\n",
    "4. **Balanceo del Dataset**:\n",
    "   - Dado que las anomalías son menos frecuentes que las imágenes normales, se deben aplicar técnicas de balanceo:\n",
    "     - **Oversampling** (aumentar el número de imágenes con anomalías) o **undersampling** (reducir las imágenes normales).\n",
    "\n",
    "### **Salidas**:\n",
    "- **Imágenes preprocesadas** en formato PNG/JPEG, listas para el entrenamiento del modelo.\n",
    "- **Conjunto de datos aumentado**: Versión aumentada de las imágenes originales para mejorar la robustez del modelo.\n",
    "- **Archivos CSV actualizados**: Con las coordenadas de las ROI, etiquetas y otras anotaciones necesarias para el entrenamiento.\n",
    "\n",
    "---\n",
    "\n",
    "## Integrante 2: Modelado, Entrenamiento y Optimización\n",
    "\n",
    "### **Entrada**:\n",
    "- **Imágenes preprocesadas y aumentadas**: Imágenes en formato PNG/JPEG, previamente procesadas por el Integrante 1.\n",
    "- **VGG16 Preentrenado**: Modelo base VGG16 con pesos preentrenados en ImageNet.\n",
    "- **Archivos CSV**: Contienen las etiquetas de clasificación (normal, benigno, maligno) y las coordenadas de las ROI.\n",
    "\n",
    "### **Tareas**:\n",
    "1. **Carga y Configuración del Modelo VGG16**:\n",
    "   - Cargar el modelo VGG16 preentrenado en ImageNet, excluyendo la capa final para adaptarlo a la clasificación de mamografías.\n",
    "   - **Congelar capas**: Las primeras capas convolucionales se congelan para mantener los pesos preentrenados, y solo se entrenan las capas superiores personalizadas.\n",
    "\n",
    "2. **Agregar Capas Personalizadas**:\n",
    "   - Añadir capas densas personalizadas (fully connected) para ajustar el modelo a la tarea específica:\n",
    "     - **Capa de aplanamiento (Flatten)** para convertir la salida convolucional en un vector.\n",
    "     - **Capas densas (Dense layers)** para mejorar la capacidad de clasificación.\n",
    "     - **Capa de salida (Softmax)** para realizar la clasificación final en tres clases: normal, benigno y maligno.\n",
    "\n",
    "3. **Entrenamiento del Modelo**:\n",
    "   - Dividir el conjunto de datos en **entrenamiento (80%)**, **validación (10%)** y **test (10%)**.\n",
    "   - Entrenar el modelo con las imágenes preprocesadas y aumentadas, utilizando **entropía cruzada ponderada** como función de pérdida para manejar el desbalance de clases.\n",
    "   - Monitorear el **rendimiento en validación cruzada**.\n",
    "\n",
    "4. **Optimización de Hiperparámetros**:\n",
    "   - Ajustar el **learning rate**, el **tamaño del batch**, el número de **épocas**, y aplicar técnicas de regularización (por ejemplo, **Dropout**) para evitar el sobreajuste.\n",
    "   \n",
    "5. **Evaluación del Modelo**:\n",
    "   - Evaluar el modelo utilizando métricas como:\n",
    "     - **Precisión, recall, F1-score**.\n",
    "     - **Curvas ROC y AUC** para ver el rendimiento del modelo en la clasificación binaria (normal vs. anormal).\n",
    "\n",
    "### **Salidas**:\n",
    "- **Modelo VGG16 ajustado y entrenado**, listo para realizar inferencias.\n",
    "- **Reportes de rendimiento** que incluyen las métricas clave (precisión, recall, F1-score).\n",
    "- **Scripts de entrenamiento** y validación que se utilizarán en futuras iteraciones.\n",
    "\n",
    "---\n",
    "\n",
    "## Integrante 3: Inferencia, Visualización y Reportes Finales\n",
    "\n",
    "### **Entrada**:\n",
    "- **Modelo entrenado**: Modelo VGG16 ajustado y entrenado por el Integrante 2.\n",
    "- **Nuevas imágenes** en formato DICOM o PNG.\n",
    "- **Archivos CSV** con coordenadas de las ROI y etiquetas de clase (si están disponibles para evaluación).\n",
    "\n",
    "### **Tareas**:\n",
    "1. **Carga y Preprocesamiento de Nuevas Imágenes**:\n",
    "   - Cargar nuevas imágenes de mamografías en formato **DICOM** o **PNG**.\n",
    "   - Aplicar el mismo preprocesamiento utilizado durante el entrenamiento:\n",
    "     - Convertir las imágenes a PNG/JPEG y redimensionarlas a **299x299 píxeles**.\n",
    "\n",
    "2. **Inferencia del Modelo**:\n",
    "   - Utilizar el modelo entrenado para realizar **predicciones** sobre las nuevas imágenes.\n",
    "   - Clasificar cada imagen como **normal**, **benigna**, o **maligna**.\n",
    "   - Generar las **coordenadas de las ROI** para resaltar las regiones sospechosas detectadas.\n",
    "\n",
    "3. **Visualización de Resultados**:\n",
    "   - Superponer las **cajas delimitadoras (ROI)** detectadas sobre las imágenes originales.\n",
    "   - Mostrar las **probabilidades** de cada clase (normal, benigno, maligno).\n",
    "   - Permitir el ajuste de los **umbrales de decisión** para modificar la sensibilidad y especificidad del modelo.\n",
    "\n",
    "4. **Generación de Reportes**:\n",
    "   - Crear **reportes visuales** que incluyan:\n",
    "     - **Matriz de confusión** para analizar la efectividad del modelo.\n",
    "     - **Curvas ROC y AUC** para evaluar la capacidad de clasificación binaria.\n",
    "   - Comparar las predicciones con las **anotaciones reales** (si están disponibles) y generar informes finales.\n",
    "\n",
    "### **Salidas**:\n",
    "- **Predicciones del modelo**: Etiquetas de clasificación (normal, benigno, maligno) y las probabilidades asociadas.\n",
    "- **Visualización de las ROI**: Cajas delimitadoras superpuestas sobre las imágenes.\n",
    "- **Reportes finales**: Incluyen las métricas de rendimiento del modelo y la comparación con las etiquetas reales.\n",
    "\n",
    "---\n",
    "\n",
    "## Flujo de Trabajo General\n",
    "\n",
    "### **Gráfico del Flujo Completo**:\n",
    "A continuación, se presenta un diagrama de flujo que muestra cómo se conectan las tareas de los tres integrantes.\n",
    "\n",
    "```mermaid\n",
    "graph TD;\n",
    "    A[Integrante 1: Preprocesamiento] --> B[Integrante 2: Modelado y Entrenamiento];\n",
    "    B --> C[Integrante 3: Inferencia y Visualización];\n",
    "    A -->|Imágenes Preprocesadas| B;\n",
    "    B -->|Modelo Entrenado| C;\n",
    "    C -->|Reportes y Visualizaciones| D[Resultados Finales];\n"
   ],
   "id": "3f4f8419ba1e634f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Este flujo de trabajo permite que los tres integrantes trabajen en paralelo:\n",
    "\n",
    "Integrante 1 puede comenzar a procesar las imágenes y generar los datos aumentados.\n",
    "\n",
    "Integrante 2 puede trabajar en el ajuste del modelo VGG16 utilizando un dataset de ejemplo si aún no se han completado las imágenes finales.\n",
    "\n",
    "Integrante 3 puede desarrollar el sistema de inferencia y visualización utilizando un modelo provisional hasta que el modelo final esté disponible.\n",
    "\n",
    "Este enfoque modular asegura que todo el equipo pueda avanzar de manera independiente y que las tareas se integren al final para producir un sistema completo de clasificación de mamografías."
   ],
   "id": "5874703f124dbfc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2becfa12614500d6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
