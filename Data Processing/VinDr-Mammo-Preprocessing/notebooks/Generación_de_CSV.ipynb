{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " CSV que combina Metadata con Finding Annotations. Si hay una fila repetida en Finding Annotations, duplica una en Metadata para no perder esa información.",
   "id": "3a823cf7fc6e5961"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-20T16:46:04.107130Z",
     "start_time": "2024-09-20T16:46:02.731469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta a los archivos CSV\n",
    "finding_annotations_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/original/Vindrmammo/finding_annotations.csv'\n",
    "metadata_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/original/Vindrmammo/metadata.csv'\n",
    "\n",
    "# Cargar los CSV en dataframes de pandas\n",
    "finding_annotations = pd.read_csv(finding_annotations_path)\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Hacer la unión de los dataframes usando 'image_id' en finding_annotations y 'SOP Instance UID' en metadata\n",
    "# Primero vamos a asegurarnos que las columnas estén correctamente nombradas y con el tipo de datos correcto\n",
    "\n",
    "# Verificar si hay columnas extra que podamos eliminar para hacer más limpia la unión\n",
    "# La columna 'image_id' en finding_annotations tiene que coincidir con 'SOP Instance UID' en metadata\n",
    "merged_df = pd.merge(finding_annotations, metadata, how='outer', left_on='image_id', right_on='SOP Instance UID')\n",
    "\n",
    "# Verificar si hay duplicados en 'image_id' y manejarlos creando filas duplicadas de 'SOP Instance UID'\n",
    "# Duplicamos las filas de image_id repetidos y mantenemos toda la información\n",
    "duplicated_image_ids = merged_df[merged_df.duplicated(subset='image_id', keep=False)]\n",
    "\n",
    "# Imprimir cuántos duplicados se encontraron\n",
    "print(f\"Se encontraron {len(duplicated_image_ids)} filas con image_id duplicados\")\n",
    "\n",
    "# Guardar el dataframe combinado en un nuevo CSV\n",
    "output_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/combined_annotations_metadata.csv'\n",
    "merged_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Archivo combinado guardado en: {output_csv_path}\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 824 filas con image_id duplicados\n",
      "Archivo combinado guardado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/combined_annotations_metadata.csv\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ahora creamos otro CSV que contenga solo las categorías \"Mass\" o \"Suscipious Calcifications\" en la columna finding annotations.\n",
    "No 2 categorías o más , ni mass y suspicious calcifications juntas. Esto es porque queremos que el sistema reconozca si es una massa o calcificacion benigna, sospechosa o maligna y al agregarle más hallazgos a una imagen esto la condiciona o aumenta las probabilidades de que sea maligna."
   ],
   "id": "458774795082573d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T16:48:01.887055Z",
     "start_time": "2024-09-20T16:48:01.690705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo CSV combinado\n",
    "combined_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/combined_annotations_metadata.csv'\n",
    "\n",
    "# Cargar el CSV combinado\n",
    "combined_df = pd.read_csv(combined_csv_path)\n",
    "\n",
    "# Filtrar las filas que tengan exactamente una categoría en 'finding_categories' que sea \"Mass\" o \"Suspicious Calcification\"\n",
    "def filter_mass_or_calcification(categories):\n",
    "    # Verificar si es una lista de una sola categoría y si esa categoría es \"Mass\" o \"Suspicious Calcification\"\n",
    "    categories_list = eval(categories) if isinstance(categories, str) else categories\n",
    "    return len(categories_list) == 1 and categories_list[0] in ['Mass', 'Suspicious Calcification']\n",
    "\n",
    "filtered_df = combined_df[combined_df['finding_categories'].apply(filter_mass_or_calcification)]\n",
    "\n",
    "# Guardar el nuevo CSV filtrado\n",
    "filtered_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_mass_calcifications.csv'\n",
    "filtered_df.to_csv(filtered_csv_path, index=False)\n",
    "\n",
    "print(f\"CSV filtrado guardado en: {filtered_csv_path}\")\n"
   ],
   "id": "7d989f4b2f2cea36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV filtrado guardado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_mass_calcifications.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora creamos un CSV con nueva columna image_name para diferenciar las imagenes que tienen varios image_id",
   "id": "89a6277be6c0b19d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T16:48:22.577967Z",
     "start_time": "2024-09-20T16:48:22.500825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al CSV filtrado\n",
    "filtered_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_mass_calcifications.csv'\n",
    "\n",
    "# Cargar el CSV filtrado\n",
    "filtered_csv = pd.read_csv(filtered_csv_path)\n",
    "\n",
    "# Crear una nueva columna 'image_name' que sea una copia inicial del 'SOP Instance UID'\n",
    "filtered_csv['image_name'] = ''\n",
    "\n",
    "# Agrupar por 'SOP Instance UID' y contar las repeticiones\n",
    "image_counts = filtered_csv.groupby('SOP Instance UID').cumcount()\n",
    "\n",
    "# Asignar el nuevo valor en 'image_name' con el formato {SOP Instance UID}_{n}\n",
    "for index, row in filtered_csv.iterrows():\n",
    "    sop_uid = row['SOP Instance UID']\n",
    "    count = image_counts[index]\n",
    "    filtered_csv.at[index, 'image_name'] = f\"{sop_uid}_{count}\"\n",
    "\n",
    "# Guardar el nuevo CSV con la columna 'image_name'\n",
    "new_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_with_image_names.csv'\n",
    "filtered_csv.to_csv(new_csv_path, index=False)\n",
    "\n",
    "print(f\"Nuevo CSV guardado en: {new_csv_path}\")\n"
   ],
   "id": "f207563f5c659e05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo CSV guardado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_with_image_names.csv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora ya tenemos el csv que necesitamos.",
   "id": "1ea6e701f8331f0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora creamos un csv que contenga no solo mass y calcification si no todas las categorías menos \"No Finding\"",
   "id": "6d786319b207efab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T11:52:11.209559Z",
     "start_time": "2024-09-26T11:52:11.031913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import ast  # Importar ast para evaluar literales de forma segura\n",
    "\n",
    "# Ruta al archivo CSV combinado\n",
    "combined_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/combined_annotations_metadata.csv'\n",
    "\n",
    "# Cargar el CSV combinado\n",
    "combined_df = pd.read_csv(combined_csv_path)\n",
    "\n",
    "# Lista de categorías a incluir\n",
    "categories_to_include = [\n",
    "    'Mass',\n",
    "    'Suspicious Calcification',\n",
    "    'Focal Asymmetry',\n",
    "    'Architectural Distortion',\n",
    "    'Asymmetry',\n",
    "    'Suspicious Lymph Node',\n",
    "    'Skin Thickening',\n",
    "    'Global Asymmetry',\n",
    "    'Nipple Retraction',\n",
    "    'Skin Retraction'\n",
    "]\n",
    "\n",
    "# Función para filtrar filas con exactamente una categoría de interés\n",
    "def filter_single_category(categories):\n",
    "    # Verificar si 'categories' es una cadena que representa una lista\n",
    "    if isinstance(categories, str):\n",
    "        try:\n",
    "            categories_list = ast.literal_eval(categories)\n",
    "        except (ValueError, SyntaxError):\n",
    "            # Si no se puede evaluar, retornamos False\n",
    "            return False\n",
    "    else:\n",
    "        categories_list = categories\n",
    "\n",
    "    # Verificar que sea una lista con exactamente una categoría de interés\n",
    "    return (\n",
    "        isinstance(categories_list, list) and\n",
    "        len(categories_list) == 1 and\n",
    "        categories_list[0] in categories_to_include\n",
    "    )\n",
    "\n",
    "# Aplicar el filtro al DataFrame\n",
    "filtered_df = combined_df[combined_df['finding_categories'].apply(filter_single_category)]\n",
    "\n",
    "# Guardar el nuevo CSV filtrado\n",
    "filtered_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_mass_calcifications_and_others.csv'\n",
    "filtered_df.to_csv(filtered_csv_path, index=False)\n",
    "\n",
    "print(f\"CSV filtrado guardado en: {filtered_csv_path}\")\n"
   ],
   "id": "e67aa718a77fcd65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV filtrado guardado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_mass_calcifications_and_others.csv\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Añadimos la columna image_name",
   "id": "d22a197fa4b29baa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T11:56:11.956679Z",
     "start_time": "2024-09-26T11:56:11.833454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al CSV filtrado (resultado del paso anterior)\n",
    "filtered_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_mass_calcifications_and_others.csv'\n",
    "\n",
    "# Cargar el CSV filtrado\n",
    "filtered_csv = pd.read_csv(filtered_csv_path)\n",
    "\n",
    "# Crear una nueva columna 'image_name' que sea una copia inicial del 'SOP Instance UID'\n",
    "filtered_csv['image_name'] = ''\n",
    "\n",
    "# Agrupar por 'SOP Instance UID' y contar las repeticiones\n",
    "image_counts = filtered_csv.groupby('SOP Instance UID').cumcount()\n",
    "\n",
    "# Asignar el nuevo valor en 'image_name' con el formato {SOP Instance UID}_{n}\n",
    "for index, row in filtered_csv.iterrows():\n",
    "    sop_uid = row['SOP Instance UID']\n",
    "    count = image_counts[index]\n",
    "    filtered_csv.at[index, 'image_name'] = f\"{sop_uid}_{count}\"\n",
    "\n",
    "# Guardar el nuevo CSV con la columna 'image_name' y el nombre de archivo ajustado\n",
    "new_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/others_with_image_names.csv'\n",
    "filtered_csv.to_csv(new_csv_path, index=False)\n",
    "\n",
    "print(f\"Nuevo CSV guardado en: {new_csv_path}\")\n"
   ],
   "id": "4d42acabefd5ffe4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo CSV guardado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/others_with_image_names.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "95a215b2943cae07"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Primeras 2500 no finding y otras anotaciones ( 1 sola por imágenes)    ",
   "id": "809237216eaf5be6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T16:17:16.886895Z",
     "start_time": "2024-10-11T16:17:16.616597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Ruta al archivo CSV combinado\n",
    "combined_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/combined_annotations_metadata.csv'\n",
    "\n",
    "# Cargar el CSV combinado\n",
    "try:\n",
    "    combined_df = pd.read_csv(combined_csv_path)\n",
    "    print(\"CSV cargado exitosamente.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: El archivo en la ruta '{combined_csv_path}' no se encontró.\")\n",
    "    exit(1)\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error al parsear el CSV: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Función para convertir la cadena de categorías a una lista de forma segura\n",
    "def parse_categories(categories):\n",
    "    if isinstance(categories, str):\n",
    "        try:\n",
    "            # Usa ast.literal_eval para mayor seguridad\n",
    "            return ast.literal_eval(categories)\n",
    "        except (ValueError, SyntaxError):\n",
    "            # Si falla, asume que es una única categoría\n",
    "            return [categories]\n",
    "    elif isinstance(categories, list):\n",
    "        return categories\n",
    "    else:\n",
    "        # Maneja otros tipos de datos inesperados\n",
    "        return []\n",
    "\n",
    "# Aplicar la función para crear una nueva columna con listas de categorías\n",
    "combined_df['categories_list'] = combined_df['finding_categories'].apply(parse_categories)\n",
    "\n",
    "# Filtrar filas que tengan exactamente una categoría\n",
    "single_category_df = combined_df[combined_df['categories_list'].apply(len) == 1].copy()\n",
    "print(f\"Filas con exactamente una categoría: {single_category_df.shape[0]}\")\n",
    "\n",
    "# Crear una nueva columna 'single_category' con la categoría única en minúsculas y sin espacios\n",
    "single_category_df['single_category'] = single_category_df['categories_list'].str[0].str.lower().str.strip()\n",
    "\n",
    "# Verificar las categorías únicas después de la normalización\n",
    "unique_categories = single_category_df['single_category'].unique()\n",
    "print(\"Categorías únicas después de la normalización:\")\n",
    "print(unique_categories)\n",
    "\n",
    "# Verificar el número de filas \"no finding\" antes de limitar\n",
    "total_no_finding = single_category_df[single_category_df['single_category'] == 'no finding'].shape[0]\n",
    "print(f\"Total de filas 'no finding' antes de filtrar: {total_no_finding}\")\n",
    "\n",
    "# Filtrar filas con \"no finding\" y tomar solo las primeras 2500\n",
    "no_finding_df = single_category_df[single_category_df['single_category'] == 'no finding'].head(2500).copy()\n",
    "filtered_no_finding = no_finding_df.shape[0]\n",
    "print(f\"Filas 'no finding' incluidas en el CSV final: {filtered_no_finding}\")\n",
    "\n",
    "# Filtrar las filas que tienen exactamente una categoría y que no sean \"no finding\"\n",
    "other_categories_df = single_category_df[single_category_df['single_category'] != 'no finding'].copy()\n",
    "other_categories_count = other_categories_df.shape[0]\n",
    "print(f\"Total de filas en otras categorías: {other_categories_count}\")\n",
    "\n",
    "# Combinar las demás categorías con las filas seleccionadas de \"no finding\"\n",
    "filtered_df = pd.concat([other_categories_df, no_finding_df], ignore_index=True)\n",
    "print(f\"Total de filas después de combinar: {filtered_df.shape[0]}\")\n",
    "\n",
    "# Opcional: Mezclar el dataframe para distribuir aleatoriamente las filas\n",
    "filtered_df = filtered_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"DataFrame mezclado aleatoriamente.\")\n",
    "\n",
    "# Contar las ocurrencias de cada categoría en el DataFrame filtrado\n",
    "category_counts = filtered_df['single_category'].value_counts()\n",
    "print(\"Distribución de categorías en el CSV filtrado:\")\n",
    "print(category_counts)\n",
    "\n",
    "# Verificar que solo hay 2500 filas \"no finding\"\n",
    "if category_counts.get('no finding', 0) > 2500:\n",
    "    print(\"Advertencia: Hay más de 2500 filas 'no finding' en el CSV filtrado.\")\n",
    "else:\n",
    "    print(\"Correcto: Las filas 'no finding' están limitadas a 2500.\")\n",
    "\n",
    "# Eliminar las columnas auxiliares si ya no se necesitan\n",
    "filtered_df = filtered_df.drop(columns=['categories_list', 'single_category'])\n",
    "print(\"Columnas auxiliares eliminadas.\")\n",
    "\n",
    "# Ruta para guardar el CSV filtrado\n",
    "filtered_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/4categories.csv'\n",
    "\n",
    "# Guardar el nuevo CSV filtrado\n",
    "try:\n",
    "    filtered_df.to_csv(filtered_csv_path, index=False)\n",
    "    print(f\"CSV filtrado guardado en: {filtered_csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el CSV: {e}\")\n"
   ],
   "id": "3dab56b0748aed0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV cargado exitosamente.\n",
      "Filas con exactamente una categoría: 20312\n",
      "Categorías únicas después de la normalización:\n",
      "['no finding' 'mass' 'suspicious calcification' 'focal asymmetry'\n",
      " 'architectural distortion' 'asymmetry' 'skin thickening'\n",
      " 'suspicious lymph node' 'global asymmetry' 'nipple retraction'\n",
      " 'skin retraction']\n",
      "Total de filas 'no finding' antes de filtrar: 18232\n",
      "Filas 'no finding' incluidas en el CSV final: 2500\n",
      "Total de filas en otras categorías: 2080\n",
      "Total de filas después de combinar: 4580\n",
      "DataFrame mezclado aleatoriamente.\n",
      "Distribución de categorías en el CSV filtrado:\n",
      "single_category\n",
      "no finding                  2500\n",
      "mass                        1123\n",
      "suspicious calcification     402\n",
      "focal asymmetry              232\n",
      "architectural distortion      95\n",
      "asymmetry                     90\n",
      "suspicious lymph node         57\n",
      "skin thickening               38\n",
      "global asymmetry              24\n",
      "nipple retraction             12\n",
      "skin retraction                7\n",
      "Name: count, dtype: int64\n",
      "Correcto: Las filas 'no finding' están limitadas a 2500.\n",
      "Columnas auxiliares eliminadas.\n",
      "CSV filtrado guardado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/4categories.csv\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T16:18:35.861769Z",
     "start_time": "2024-10-11T16:18:35.857436Z"
    }
   },
   "cell_type": "code",
   "source": "#Añadimos la columna image name",
   "id": "6c8c3be631b97312",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T16:19:01.213323Z",
     "start_time": "2024-10-11T16:19:01.046786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al CSV filtrado (resultado del paso anterior)\n",
    "filtered_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/4categories.csv'\n",
    "\n",
    "# Cargar el CSV filtrado\n",
    "filtered_csv = pd.read_csv(filtered_csv_path)\n",
    "\n",
    "# Crear una nueva columna 'image_name' que sea una copia inicial del 'SOP Instance UID'\n",
    "filtered_csv['image_name'] = ''\n",
    "\n",
    "# Agrupar por 'SOP Instance UID' y contar las repeticiones\n",
    "image_counts = filtered_csv.groupby('SOP Instance UID').cumcount()\n",
    "\n",
    "# Asignar el nuevo valor en 'image_name' con el formato {SOP Instance UID}_{n}\n",
    "for index, row in filtered_csv.iterrows():\n",
    "    sop_uid = row['SOP Instance UID']\n",
    "    count = image_counts[index]\n",
    "    filtered_csv.at[index, 'image_name'] = f\"{sop_uid}_{count}\"\n",
    "\n",
    "# Guardar el nuevo CSV con la columna 'image_name' y el nombre de archivo ajustado\n",
    "new_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/4categories_with_image_names.csv'\n",
    "filtered_csv.to_csv(new_csv_path, index=False)\n",
    "\n",
    "print(f\"Nuevo CSV guardado en: {new_csv_path}\")\n"
   ],
   "id": "2edee04f853c320e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo CSV guardado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/4categories_with_image_names.csv\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "62c9a61ca3301ee0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
