{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " CSV que combina Metadata con Finding Annotations. Si hay una fila repetida en Finding Annotations, duplica una en Metadata para no perder esa información.",
   "id": "3a823cf7fc6e5961"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-20T16:46:04.107130Z",
     "start_time": "2024-09-20T16:46:02.731469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta a los archivos CSV\n",
    "finding_annotations_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/original/Vindrmammo/finding_annotations.csv'\n",
    "metadata_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/original/Vindrmammo/metadata.csv'\n",
    "\n",
    "# Cargar los CSV en dataframes de pandas\n",
    "finding_annotations = pd.read_csv(finding_annotations_path)\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Hacer la unión de los dataframes usando 'image_id' en finding_annotations y 'SOP Instance UID' en metadata\n",
    "# Primero vamos a asegurarnos que las columnas estén correctamente nombradas y con el tipo de datos correcto\n",
    "\n",
    "# Verificar si hay columnas extra que podamos eliminar para hacer más limpia la unión\n",
    "# La columna 'image_id' en finding_annotations tiene que coincidir con 'SOP Instance UID' en metadata\n",
    "merged_df = pd.merge(finding_annotations, metadata, how='outer', left_on='image_id', right_on='SOP Instance UID')\n",
    "\n",
    "# Verificar si hay duplicados en 'image_id' y manejarlos creando filas duplicadas de 'SOP Instance UID'\n",
    "# Duplicamos las filas de image_id repetidos y mantenemos toda la información\n",
    "duplicated_image_ids = merged_df[merged_df.duplicated(subset='image_id', keep=False)]\n",
    "\n",
    "# Imprimir cuántos duplicados se encontraron\n",
    "print(f\"Se encontraron {len(duplicated_image_ids)} filas con image_id duplicados\")\n",
    "\n",
    "# Guardar el dataframe combinado en un nuevo CSV\n",
    "output_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/combined_annotations_metadata.csv'\n",
    "merged_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Archivo combinado guardado en: {output_csv_path}\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 824 filas con image_id duplicados\n",
      "Archivo combinado guardado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/combined_annotations_metadata.csv\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ahora creamos otro CSV que contenga solo las categorías \"Mass\" o \"Suscipious Calcifications\" en la columna finding annotations.\n",
    "No 2 categorías o más , ni mass y suspicious calcifications juntas. Esto es porque queremos que el sistema reconozca si es una massa o calcificacion benigna, sospechosa o maligna y al agregarle más hallazgos a una imagen esto la condiciona o aumenta las probabilidades de que sea maligna."
   ],
   "id": "458774795082573d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T16:48:01.887055Z",
     "start_time": "2024-09-20T16:48:01.690705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo CSV combinado\n",
    "combined_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/combined_annotations_metadata.csv'\n",
    "\n",
    "# Cargar el CSV combinado\n",
    "combined_df = pd.read_csv(combined_csv_path)\n",
    "\n",
    "# Filtrar las filas que tengan exactamente una categoría en 'finding_categories' que sea \"Mass\" o \"Suspicious Calcification\"\n",
    "def filter_mass_or_calcification(categories):\n",
    "    # Verificar si es una lista de una sola categoría y si esa categoría es \"Mass\" o \"Suspicious Calcification\"\n",
    "    categories_list = eval(categories) if isinstance(categories, str) else categories\n",
    "    return len(categories_list) == 1 and categories_list[0] in ['Mass', 'Suspicious Calcification']\n",
    "\n",
    "filtered_df = combined_df[combined_df['finding_categories'].apply(filter_mass_or_calcification)]\n",
    "\n",
    "# Guardar el nuevo CSV filtrado\n",
    "filtered_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_mass_calcifications.csv'\n",
    "filtered_df.to_csv(filtered_csv_path, index=False)\n",
    "\n",
    "print(f\"CSV filtrado guardado en: {filtered_csv_path}\")\n"
   ],
   "id": "7d989f4b2f2cea36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV filtrado guardado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_mass_calcifications.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora creamos un CSV con nueva columna image_name para diferenciar las imagenes que tienen varios image_id",
   "id": "89a6277be6c0b19d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T16:48:22.577967Z",
     "start_time": "2024-09-20T16:48:22.500825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al CSV filtrado\n",
    "filtered_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_mass_calcifications.csv'\n",
    "\n",
    "# Cargar el CSV filtrado\n",
    "filtered_csv = pd.read_csv(filtered_csv_path)\n",
    "\n",
    "# Crear una nueva columna 'image_name' que sea una copia inicial del 'SOP Instance UID'\n",
    "filtered_csv['image_name'] = ''\n",
    "\n",
    "# Agrupar por 'SOP Instance UID' y contar las repeticiones\n",
    "image_counts = filtered_csv.groupby('SOP Instance UID').cumcount()\n",
    "\n",
    "# Asignar el nuevo valor en 'image_name' con el formato {SOP Instance UID}_{n}\n",
    "for index, row in filtered_csv.iterrows():\n",
    "    sop_uid = row['SOP Instance UID']\n",
    "    count = image_counts[index]\n",
    "    filtered_csv.at[index, 'image_name'] = f\"{sop_uid}_{count}\"\n",
    "\n",
    "# Guardar el nuevo CSV con la columna 'image_name'\n",
    "new_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_with_image_names.csv'\n",
    "filtered_csv.to_csv(new_csv_path, index=False)\n",
    "\n",
    "print(f\"Nuevo CSV guardado en: {new_csv_path}\")\n"
   ],
   "id": "f207563f5c659e05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo CSV guardado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_with_image_names.csv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora ya tenemos el csv que necesitamos.",
   "id": "1ea6e701f8331f0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8e1961ede12f2b4b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
