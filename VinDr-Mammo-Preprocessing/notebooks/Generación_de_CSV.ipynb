{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### CSV que combina Metadata con Finding Annotations.\n",
    "### Si hay una fila repetida en Finding Annotations, duplica una en Metadata para no perder esa información."
   ],
   "id": "3a823cf7fc6e5961"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-12T12:18:55.197235Z",
     "start_time": "2024-09-12T12:18:54.903190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta a los archivos CSV\n",
    "finding_annotations_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/original/Vindrmammo/finding_annotations.csv'\n",
    "metadata_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/original/Vindrmammo/metadata.csv'\n",
    "\n",
    "# Cargar los CSV en dataframes de pandas\n",
    "finding_annotations = pd.read_csv(finding_annotations_path)\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Hacer la unión de los dataframes usando 'image_id' en finding_annotations y 'SOP Instance UID' en metadata\n",
    "# Primero vamos a asegurarnos que las columnas estén correctamente nombradas y con el tipo de datos correcto\n",
    "\n",
    "# Verificar si hay columnas extra que podamos eliminar para hacer más limpia la unión\n",
    "# La columna 'image_id' en finding_annotations tiene que coincidir con 'SOP Instance UID' en metadata\n",
    "merged_df = pd.merge(finding_annotations, metadata, how='outer', left_on='image_id', right_on='SOP Instance UID')\n",
    "\n",
    "# Verificar si hay duplicados en 'image_id' y manejarlos creando filas duplicadas de 'SOP Instance UID'\n",
    "# Duplicamos las filas de image_id repetidos y mantenemos toda la información\n",
    "duplicated_image_ids = merged_df[merged_df.duplicated(subset='image_id', keep=False)]\n",
    "\n",
    "# Imprimir cuántos duplicados se encontraron\n",
    "print(f\"Se encontraron {len(duplicated_image_ids)} filas con image_id duplicados\")\n",
    "\n",
    "# Guardar el dataframe combinado en un nuevo CSV\n",
    "output_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/combined_annotations_metadata.csv'\n",
    "merged_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Archivo combinado guardado en: {output_csv_path}\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 824 filas con image_id duplicados\n",
      "Archivo combinado guardado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/combined_annotations_metadata.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Ahora creamos otro CSV que contenga solo las categorías \"Mass\" o \"Suscipious Calcifications\" en la columna finding annotations\n",
    "### No 2 categorías o más , ni mass y suspicious calcifications juntas. Esto es porque queremos que el sistema reconozca si es una massa o calcificacion\n",
    "### bening, sospechosa o maligna y al agregarle más hallazgos a una imagen esto la condiciona o aumenta las probabilidades de que sea maligna."
   ],
   "id": "458774795082573d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T12:35:39.117942Z",
     "start_time": "2024-09-12T12:35:38.923192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo CSV combinado\n",
    "combined_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/combined_annotations_metadata.csv'\n",
    "\n",
    "# Cargar el CSV combinado\n",
    "combined_df = pd.read_csv(combined_csv_path)\n",
    "\n",
    "# Filtrar las filas que tengan exactamente una categoría en 'finding_categories' que sea \"Mass\" o \"Suspicious Calcification\"\n",
    "def filter_mass_or_calcification(categories):\n",
    "    # Verificar si es una lista de una sola categoría y si esa categoría es \"Mass\" o \"Suspicious Calcification\"\n",
    "    categories_list = eval(categories) if isinstance(categories, str) else categories\n",
    "    return len(categories_list) == 1 and categories_list[0] in ['Mass', 'Suspicious Calcification']\n",
    "\n",
    "filtered_df = combined_df[combined_df['finding_categories'].apply(filter_mass_or_calcification)]\n",
    "\n",
    "# Guardar el nuevo CSV filtrado\n",
    "filtered_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_mass_calcifications.csv'\n",
    "filtered_df.to_csv(filtered_csv_path, index=False)\n",
    "\n",
    "print(f\"CSV filtrado guardado en: {filtered_csv_path}\")\n"
   ],
   "id": "7d989f4b2f2cea36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV filtrado guardado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_mass_calcifications.csv\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Ahora creamos un CSV con nueva columna image_name para diferenciar las imagenes que tienen varios image_id",
   "id": "89a6277be6c0b19d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T15:26:13.615015Z",
     "start_time": "2024-09-12T15:26:13.487324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al CSV filtrado\n",
    "filtered_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_mass_calcifications.csv'\n",
    "\n",
    "# Cargar el CSV filtrado\n",
    "filtered_csv = pd.read_csv(filtered_csv_path)\n",
    "\n",
    "# Crear una nueva columna 'image_name' que sea una copia inicial del 'SOP Instance UID'\n",
    "filtered_csv['image_name'] = ''\n",
    "\n",
    "# Agrupar por 'SOP Instance UID' y contar las repeticiones\n",
    "image_counts = filtered_csv.groupby('SOP Instance UID').cumcount()\n",
    "\n",
    "# Asignar el nuevo valor en 'image_name' con el formato {SOP Instance UID}_{n}\n",
    "for index, row in filtered_csv.iterrows():\n",
    "    sop_uid = row['SOP Instance UID']\n",
    "    count = image_counts[index]\n",
    "    filtered_csv.at[index, 'image_name'] = f\"{sop_uid}_{count}\"\n",
    "\n",
    "# Guardar el nuevo CSV con la columna 'image_name'\n",
    "new_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_with_image_names.csv'\n",
    "filtered_csv.to_csv(new_csv_path, index=False)\n",
    "\n",
    "print(f\"Nuevo CSV guardado en: {new_csv_path}\")\n"
   ],
   "id": "f207563f5c659e05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo CSV guardado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_with_image_names.csv\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Este es un csv que toma filtered y elimina las filas duplicas de image_id",
   "id": "34d9e07efc270796"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T15:55:32.425626Z",
     "start_time": "2024-09-12T15:55:32.360697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al CSV filtrado original\n",
    "filtered_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_mass_calcifications.csv'\n",
    "\n",
    "# Cargar el CSV filtrado\n",
    "filtered_df = pd.read_csv(filtered_csv_path)\n",
    "\n",
    "# Eliminar las filas duplicadas basadas en 'image_id', conservando solo la primera aparición\n",
    "filtered_unique_df = filtered_df.drop_duplicates(subset='image_id', keep='first')\n",
    "\n",
    "# Guardar el nuevo CSV con las filas únicas por 'image_id'\n",
    "unique_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_unique_mass_calcifications.csv'\n",
    "filtered_unique_df.to_csv(unique_csv_path, index=False)\n",
    "\n",
    "print(f\"Nuevo CSV guardado en: {unique_csv_path}\")\n"
   ],
   "id": "24c9845cd37f8a1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo CSV guardado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/filtered_unique_mass_calcifications.csv\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Función para hacer un csv para combinar metadata, con annotation y que esté filtrado con no finding y monochorme 2 si es necesario en algun momento",
   "id": "a762bd48537fd235"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T18:58:25.422097Z",
     "start_time": "2024-09-12T18:58:25.305225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del dataset\n",
    "csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/combined_annotations_metadata.csv'\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Limpiar la columna 'finding_categories' eliminando los caracteres [' y ']\n",
    "df['finding_categories'] = df['finding_categories'].str.strip(\"[]'\")\n",
    "\n",
    "# Verificar que se haya limpiado correctamente\n",
    "print(\"Primeros valores después de la limpieza:\")\n",
    "print(df['finding_categories'].head(10))\n",
    "\n",
    "# Filtrar las filas que sean 'No Finding' en 'finding_categories' y 'MONOCHROME2' en 'Photometric Interpretation'\n",
    "filtered_df = df[(df['finding_categories'] == 'No Finding') & (df['Photometric Interpretation'] == 'MONOCHROME2')]\n",
    "\n",
    "# Tomar las primeras 200 filas con esas características\n",
    "filtered_200_df = filtered_df.head(200)\n",
    "\n",
    "# Guardar en un nuevo CSV\n",
    "output_csv_path = '/Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/combined_metadata_no_finding.csv'\n",
    "filtered_200_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Se ha guardado el archivo filtrado en: {output_csv_path}\")\n"
   ],
   "id": "25f7cab4d198524c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros valores después de la limpieza:\n",
      "0    No Finding\n",
      "1    No Finding\n",
      "2    No Finding\n",
      "3    No Finding\n",
      "4    No Finding\n",
      "5    No Finding\n",
      "6    No Finding\n",
      "7    No Finding\n",
      "8    No Finding\n",
      "9          Mass\n",
      "Name: finding_categories, dtype: object\n",
      "Se ha guardado el archivo filtrado en: /Volumes/m2/Memoria/Code/PMM/VinDr-Mammo-Preprocessing/data/processed/csv/combined_metadata_no_finding.csv\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7c1f1129ab39b8f4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
